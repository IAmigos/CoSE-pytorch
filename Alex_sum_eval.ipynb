{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils import set_seed\n",
    "from data.loaders import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'ajimenez'\n",
    "path_to_model = f\"/home/{user}/CoSE-pytorch/wandb/latest-run/files/weights_trained/epoch_150\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(0)\n",
    "device = torch.device('cuda:0')\n",
    "cose = CoSEModel('config.json', False)\n",
    "cose.encoder.load_state_dict(torch.load(os.path.join(os.getcwd(), path_to_model,\"encoder.pth\"), map_location=device))\n",
    "cose.decoder.load_state_dict(torch.load(os.path.join(os.getcwd(),path_to_model ,\"decoder.pth\"), map_location=device))\n",
    "cose.position_predictive_model.load_state_dict(torch.load(os.path.join(os.getcwd(),path_to_model,\"pos_pred.pth\"), map_location=device))\n",
    "cose.embedding_predictive_model.load_state_dict(torch.load(os.path.join(os.getcwd(),path_to_model,\"emb_pred.pth\"), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cose.encoder = cose.encoder.eval()\n",
    "cose.decoder = cose.decoder.eval()\n",
    "cose.embedding_predictive_model = cose.embedding_predictive_model.eval()\n",
    "cose.position_predictive_model = cose.position_predictive_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = f\"/data/{user}/cose/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchdata = BatchCoSELoader(path = val_path,\n",
    "                    filenames={\"inputs_file\" : \"inputs_list_based.pkl\",\n",
    "                               \"targets_file\": \"target_list_based.pkl\"\n",
    "                              }\n",
    "                )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "                    dataset =batchdata,\n",
    "                    batch_size = 1, #data is already in batch mode, batch_size = 1 means iterating every .get_next() returns a new batch\n",
    "                )\n",
    "stats_json = 'didi_wo_text-stats-origin_abs_pos.json'\n",
    "stats_path = '/data/jcabrera/didi_wo_text/'\n",
    "with open(os.path.join(stats_path, stats_json)) as json_file:\n",
    "    stats = json.load(json_file)\n",
    "\n",
    "mean_channel = stats['mean_channel'][:2]\n",
    "std_channel = np.sqrt(stats['var_channel'][:2])\n",
    "log_dir = f'/home/ajimenez/pruebas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = AggregateAvg()\n",
    "models_quant_eval = [cose.embedding_predictive_model, cose.decoder]\n",
    "models_qual_eval = [cose.position_predictive_model, cose.embedding_predictive_model, cose.decoder]\n",
    "stats_tuple = [mean_channel, std_channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch_input, batch_target in iter(valid_loader):\n",
    "    if i == 1:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_eval_parse_input = eval_parse_input(batch_input, cose.device)\n",
    "out_eval_parse_target = eval_parse_target(batch_target, cose.device)\n",
    "encoder_inputs, _, strok_len_inputs, _, _ = out_eval_parse_input\n",
    "# passing inputs to encoding\n",
    "comb_mask, look_ahead_mask, _ = generate_3d_mask(encoder_inputs, strok_len_inputs,cose.device, cose.config.enc_nhead)\n",
    "encoder_out = cose.encoder(encoder_inputs.permute(1,0,2), strok_len_inputs, comb_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 862 ms, sys: 0 ns, total: 862 ms\n",
      "Wall time: 590 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eval_loss, recon_chamfer, pred_chamfer = quantitative_eval_step(encoder_out, out_eval_parse_input, out_eval_parse_target, models_quant_eval, stats_tuple, eval_loss, cose.device, cose.config.rel_nhead )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rc_chamfer_stroke': 0.04273923939346498,\n",
       "  'nll_embedding': -2.6050239,\n",
       "  'pred_chamfer_stroke': 0.05665886122275145},\n",
       " 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss.summary_and_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 646 Âµs, total: 2.44 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_batch_stroke, predicted_batch_strat_pos, draw_seq_len = qualitative_eval_step(encoder_out, out_eval_parse_input, out_eval_parse_target, models_qual_eval, stats_tuple, cose.device, cose.config.rel_nhead, num_extra_pred = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old test_strokes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "    def test_strokes(self, valid_loader):\n",
    "\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "        self.embedding_predictive_model.eval()\n",
    "        self.position_predictive_model.eval()\n",
    "\n",
    "\n",
    "        mean_channel, std_channel = get_stats(self.config.stats_path)\n",
    "        \n",
    "        num_batch = 0\n",
    "\n",
    "        list_name_files = []\n",
    "        list_recon_cd = []\n",
    "        list_pred_cd = []\n",
    "        list_loss_eval_ae = []\n",
    "        list_loss_eval_pos = []\n",
    "        list_loss_eval_emb = []\n",
    "        \n",
    "        for batch_input, batch_target in iter(valid_loader):\n",
    "\n",
    "            num_batch = num_batch + 1\n",
    "            encoder_inputs = batch_input['encoder_inputs'].squeeze(dim = 0).to(self.device)\n",
    "            num_strokes = batch_input['num_strokes'].squeeze(dim = 0).to(self.device)\n",
    "            strok_len_inputs = batch_input['seq_len'].squeeze(dim = 0).to(self.device)\n",
    "            start_coord = batch_input['start_coord'].squeeze(dim = 0).squeeze().to(self.device)\n",
    "            #forward autoregressive\n",
    "            with torch.no_grad():\n",
    "                comb_mask, look_ahead_mask, _ = generate_3d_mask(encoder_inputs, strok_len_inputs,self.device, self.config.enc_nhead)\n",
    "                encoder_out = self.encoder(encoder_inputs.permute(1,0,2), strok_len_inputs, comb_mask)\n",
    "                diagram_embedding, padded_max_num_strokes, _, num_diagrams = reshape_stroke2diagram(encoder_out,num_strokes)\n",
    "                start_pos_base = start_coord.reshape(num_diagrams,padded_max_num_strokes,2)\n",
    "                #calculate recon_cd, pred_cd, diagram output\n",
    "                loss_eval_ae, recon_cd, _ = get_reconstruction_metrics(expected_strokes=encoder_inputs,\n",
    "                                                                       expected_start_coord=start_coord,\n",
    "                                                                       pred_embedding =encoder_out,\n",
    "                                                                       recon_start_coord=start_coord,\n",
    "                                                                       strok_len_inputs=strok_len_inputs,\n",
    "                                                                       decoder=self.decoder,\n",
    "                                                                       mean_channel = mean_channel,\n",
    "                                                                       std_channel=std_channel,\n",
    "                                                                       device = self.device)\n",
    "                \n",
    "                loss_eval_emb, loss_eval_pos, pred_cd, recons_strokes, recons_start_pos = get_prediction_metrics(encoder_inputs =encoder_inputs,\n",
    "                                                                                                                 strok_len_inputs = strok_len_inputs,\n",
    "                                                                                                                 diagram_embedding = diagram_embedding,\n",
    "                                                                                                                 start_pos_base = start_pos_base,\n",
    "                                                                                                                  num_strokes = num_strokes,\n",
    "                                                                                                                 models = [self.decoder, self.position_predictive_model, self.embedding_predictive_model],\n",
    "                                                                                                                 device = self.device,\n",
    "                                                                                                                 mean_channel = mean_channel,\n",
    "                                                                                                                 std_channel = std_channel,\n",
    "                                                                                                                 use_autoregressive = False)\n",
    "            \n",
    "            list_recon_cd.append(recon_cd.item()) \n",
    "            list_pred_cd.append(pred_cd.item())\n",
    "            list_loss_eval_ae.append(loss_eval_ae.item())\n",
    "            list_loss_eval_pos.append(loss_eval_pos.item())\n",
    "            list_loss_eval_emb.append(loss_eval_emb.item())\n",
    "\n",
    "            if num_batch==1:\n",
    "                num_diagrams = len(recons_strokes)\n",
    "                #save image\n",
    "                for i_diagram in range(num_diagrams):\n",
    "                    recons_strokes_padded_i = torch.nn.utils.rnn.pad_sequence(recons_strokes[i_diagram], batch_first=True, padding_value=0.0).cpu().detach()\n",
    "                    seq_len_i = torch.tensor([len(i) for i in recons_strokes[i_diagram]]).cpu().detach()\n",
    "                    recons_start_pos_i = recons_start_pos[i_diagram].squeeze().cpu().detach()\n",
    "                    num_strokes_i = torch.tensor(len(recons_strokes[i_diagram])).cpu().detach()\n",
    "                    \n",
    "                    npfig, fig, _, file_save_path = self.tranform2image(recons_strokes_padded_i, seq_len_i, recons_start_pos_i, mean_channel, std_channel, num_strokes_i, file_save_name=\"diagrama_n_{}\".format(i_diagram))\n",
    "                    list_name_files.append(file_save_path)\n",
    "\n",
    "        return (np.mean(list_recon_cd), np.mean(list_pred_cd), np.mean(list_loss_eval_ae),np.mean(list_loss_eval_pos), np.mean(list_loss_eval_emb), list_name_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
