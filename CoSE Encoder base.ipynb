{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prueba Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/54/eb/4a3642e971f404d69d4f6fa3885559d67562801b99d7592487f1ecc4e017/pip-20.3.3-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 863kB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-20.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36718lines [00:00, 36817.75lines/s]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import torch\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "url = 'https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip'\n",
    "test_filepath, valid_filepath, train_filepath = extract_archive(download_from_url(url))\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer,\n",
    "                                      iter(io.open(train_filepath,\n",
    "                                                   encoding=\"utf8\"))))\n",
    "\n",
    "def data_process(raw_text_iter):\n",
    "  data = [torch.tensor([vocab[token] for token in tokenizer(item)],\n",
    "                       dtype=torch.long) for item in raw_text_iter]\n",
    "  return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "train_data = data_process(iter(io.open(train_filepath, encoding=\"utf8\")))\n",
    "val_data = data_process(iter(io.open(valid_filepath, encoding=\"utf8\")))\n",
    "test_data = data_process(iter(io.open(test_filepath, encoding=\"utf8\")))\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data[:5000], batch_size)\n",
    "val_data = batchify(val_data[:5000], eval_batch_size)\n",
    "test_data = batchify(test_data[:5000], eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        optimizer.zero_grad()\n",
    "        if data.size(0) != bptt:\n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            if data.size(0) != bptt:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            output = eval_model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.26s | valid loss 12.81 | valid ppl 367431.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.14s | valid loss  9.78 | valid ppl 17670.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.11s | valid loss  9.83 | valid ppl 18661.65\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 3 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  9.40 | test ppl 12118.95\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f15e68a7b70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f15e68a7e48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.Stream device=cuda:0 cuda_stream=0x0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARQUITECTURA TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64 #None#\n",
    "dff = 128#\n",
    "nhead = 4#\n",
    "nlayers = 6#\n",
    "dropout = 0#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderModel(nn.Module):\n",
    "    \"\"\"\n",
    "    1. With positional encoding and look-ahead masks,\n",
    "    2. With positional encoding and without look-ahead masks in a bi-directional fashion,\n",
    "    3. Without positional encoding and without look-ahead masks, which corresponds to modelling\n",
    "    the points in a stroke as set of points.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead, dff, nlayers, dropout = 0.2):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, dff, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.d_model = d_model\n",
    "        self.init_weights()\n",
    "        \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        #self.transformer_encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EncoderModel(d_model, nhead, dff, nlayers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==1.7.1 in ./.local/lib/python3.6/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.6/site-packages (from torch==1.7.1) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.6/site-packages (from torch==1.7.1) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in ./.local/lib/python3.6/site-packages (from torch==1.7.1) (0.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tfrecord\n",
      "  Downloading tfrecord-1.11.tar.gz (9.0 kB)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.6/site-packages (from tfrecord) (1.19.5)\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.6/site-packages (from tfrecord) (3.14.0)\n",
      "Requirement already satisfied: six>=1.9 in ./.local/lib/python3.6/site-packages (from protobuf->tfrecord) (1.15.0)\n",
      "Building wheels for collected packages: tfrecord\n",
      "  Building wheel for tfrecord (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tfrecord: filename=tfrecord-1.11-py3-none-any.whl size=10785 sha256=a9828ff44e7e6c714df02320fed50f54fba2a2b00e89fba68c48f39d25b7aafc\n",
      "  Stored in directory: /home/ajimenez/.cache/pip/wheels/17/92/23/6413fae5357b54e6ebcfda2a4a2f6cf086b6e10414581df8d3\n",
      "Successfully built tfrecord\n",
      "Installing collected packages: tfrecord\n",
      "Successfully installed tfrecord-1.11\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.7.1\n",
    "!pip3 install tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tfrecord.torch.dataset import TFRecordDataset\n",
    "import tensorflow as tf\n",
    "path_data = \"/data/jcabrera/didi_wo_text/training/\"\n",
    "name_file = \"diagrams_wo_text_20200131-00000-of-00010\"\n",
    "tfrecord_path = path_data + name_file\n",
    "index_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': tensor([[ 48,  48,  51,  48,  55,  56,  57,  97,  57,  54,  97,  97, 101,  55,\n",
      "         101,  97]], dtype=torch.uint8), 'label_id': tensor([[101,  50,  51,  56,  56,  97, 100,  56,  55,  98, 102,  55,  97,  52,\n",
      "          98,  54,  49,  97,  51,  99,  52,  97,  55,  52, 102,  51,  49,  53,\n",
      "          48, 101,  51, 100,  98,  97,  57,  56,  49, 100,  49,  97]],\n",
      "       dtype=torch.uint8), 'ink': tensor([[0.1517, 0.5780, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), 'stroke_length': tensor([[ 32,  32,  25,  43, 128,  31,  33,  34,  29]], dtype=torch.int32), 'shape': tensor([[  9, 128,   4]], dtype=torch.int32), 'num_strokes': tensor([[9]], dtype=torch.int32), 'rdp_ink': tensor([[187.4000, 751.9100,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]), 'rdp_stroke_length': tensor([[38, 36, 33, 21, 29, 19, 16, 13, 16]], dtype=torch.int32), 'rdp_shape': tensor([[ 9, 38,  4]], dtype=torch.int32), 'rdp_num_strokes': tensor([[9]], dtype=torch.int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajimenez/.local/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py:63: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1517, 0.5780, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = {\"key\": \"byte\", \"label_id\":\"byte\",\n",
    "               \"ink\":\"float\", \"stroke_length\":\"int\", \"shape\":\"int\", \"num_strokes\":\"int\", \n",
    "               \"rdp_ink\":\"float\", \"rdp_stroke_length\":\"int\", \n",
    "               \"rdp_shape\":\"int\", \"rdp_num_strokes\":\"int\",\n",
    "               }\n",
    "dataset = TFRecordDataset(tfrecord_path, index_path, description)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "dataiter = iter(loader)\n",
    "data = dataiter.next()\n",
    "print(data)\n",
    "data[\"ink\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(128, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6853e-01,  0.0000e+00,  0.0000e+00,  ...,  1.1111e+00,\n",
       "           0.0000e+00,  2.2222e+00],\n",
       "         [ 0.0000e+00,  1.1111e+00,  0.0000e+00,  ...,  1.1111e+00,\n",
       "           0.0000e+00,  1.1111e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.1111e+00,\n",
       "           0.0000e+00,  1.1111e+00],\n",
       "         [ 0.0000e+00,  1.1111e+00,  0.0000e+00,  ...,  1.1111e+00,\n",
       "           0.0000e+00,  1.1111e+00]],\n",
       "\n",
       "        [[ 2.2037e+00,  6.9043e-01,  1.1020e+03,  ...,  1.1111e+00,\n",
       "           1.2831e-04,  2.2222e+00],\n",
       "         [ 9.3497e-01,  6.0034e-01,  0.0000e+00,  ...,  1.1111e+00,\n",
       "           1.2831e-04,  1.1111e+00],\n",
       "         [ 9.3497e-01,  0.0000e+00,  8.4636e-01,  ...,  1.1111e+00,\n",
       "           1.2831e-04,  1.1111e+00],\n",
       "         [ 9.3497e-01,  6.0034e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           1.2831e-04,  0.0000e+00]],\n",
       "\n",
       "        [[ 3.2972e+00,  2.4377e-01,  2.1922e+03,  ...,  0.0000e+00,\n",
       "           2.5662e-04,  0.0000e+00],\n",
       "         [ 1.0103e+00, -4.6239e-01,  1.0967e+00,  ...,  1.1111e+00,\n",
       "           2.5662e-04,  1.1111e+00],\n",
       "         [ 1.0103e+00, -4.6239e-01,  1.0967e+00,  ...,  1.1111e+00,\n",
       "           2.5662e-04,  1.1111e+00],\n",
       "         [ 1.0103e+00, -4.6239e-01,  1.0967e+00,  ...,  1.1111e+00,\n",
       "           2.5662e-04,  1.1111e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4587e+00,  1.9083e+00,  9.0901e+03,  ...,  1.1111e+00,\n",
       "           7.6985e-04,  1.1111e+00],\n",
       "         [-3.1046e-01,  1.0669e+00, -9.8380e-01,  ...,  1.1111e+00,\n",
       "           7.6985e-04,  1.1111e+00],\n",
       "         [-0.0000e+00,  1.0669e+00, -0.0000e+00,  ...,  1.1111e+00,\n",
       "           7.6985e-04,  1.1111e+00],\n",
       "         [-3.1046e-01,  1.0669e+00, -9.8380e-01,  ...,  1.1111e+00,\n",
       "           7.6985e-04,  1.1111e+00]],\n",
       "\n",
       "        [[ 1.4352e+00,  1.7510e+00,  1.0526e+04,  ...,  1.1111e+00,\n",
       "           8.9816e-04,  1.1111e+00],\n",
       "         [ 7.2999e-01,  8.3767e-01, -2.4403e-01,  ...,  1.1111e+00,\n",
       "           8.9816e-04,  1.1111e+00],\n",
       "         [ 7.2999e-01,  0.0000e+00, -2.4403e-01,  ...,  1.1111e+00,\n",
       "           8.9816e-04,  1.1111e+00],\n",
       "         [ 7.2999e-01,  8.3767e-01, -2.4403e-01,  ...,  1.1111e+00,\n",
       "           8.9816e-04,  1.1111e+00]],\n",
       "\n",
       "        [[ 1.7947e+00,  0.0000e+00,  1.1615e+04,  ...,  1.1111e+00,\n",
       "           1.0265e-03,  1.1111e+00],\n",
       "         [ 1.0993e+00, -0.0000e+00,  6.6758e-01,  ...,  1.1111e+00,\n",
       "           1.0265e-03,  1.1111e+00],\n",
       "         [ 1.0993e+00, -1.6167e-01,  6.6758e-01,  ...,  1.1111e+00,\n",
       "           1.0265e-03,  1.1111e+00],\n",
       "         [ 1.0993e+00, -1.6167e-01,  6.6758e-01,  ...,  1.1111e+00,\n",
       "           1.0265e-03,  1.1111e+00]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.forward(data['ink'].reshape(9,4,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2987, in run_cell_async\n",
      "    cell = self.transform_cell(raw_cell)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3104, in transform_cell\n",
      "    cell = self.input_transformer_manager.transform_cell(raw_cell)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 590, in transform_cell\n",
      "    lines = self.do_token_transforms(lines)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 575, in do_token_transforms\n",
      "    changed, lines = self.do_one_token_transform(lines)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 555, in do_one_token_transform\n",
      "    tokens_by_line = make_tokens_by_line(lines)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 484, in make_tokens_by_line\n",
      "    for token in tokenize.generate_tokens(iter(lines).__next__):\n",
      "  File \"/usr/lib/python3.6/tokenize.py\", line 606, in _tokenize\n",
      "    pseudomatch = _compile(PseudoToken).match(line, pos)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2987, in run_cell_async\n",
      "    cell = self.transform_cell(raw_cell)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3104, in transform_cell\n",
      "    cell = self.input_transformer_manager.transform_cell(raw_cell)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 590, in transform_cell\n",
      "    lines = self.do_token_transforms(lines)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 575, in do_token_transforms\n",
      "    changed, lines = self.do_one_token_transform(lines)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 555, in do_one_token_transform\n",
      "    tokens_by_line = make_tokens_by_line(lines)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/inputtransformer2.py\", line 484, in make_tokens_by_line\n",
      "    for token in tokenize.generate_tokens(iter(lines).__next__):\n",
      "  File \"/usr/lib/python3.6/tokenize.py\", line 606, in _tokenize\n",
      "    pseudomatch = _compile(PseudoToken).match(line, pos)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 265, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 762, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 769, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 762, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n",
      "    return callable(*args, **kwargs)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2900, in _run_cell\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 998, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.6/logging/__init__.py\", line 978, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 5] Input/output error\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n",
      "    return callable(*args, **kwargs)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 250, in wrapper\n",
      "    runner = Runner(ctx_run, result, future, yielded)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 741, in __init__\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n",
      "    return callable(*args, **kwargs)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 362, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 250, in wrapper\n",
      "    runner = Runner(ctx_run, result, future, yielded)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 741, in __init__\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/contextvars/__init__.py\", line 38, in run\n",
      "    return callable(*args, **kwargs)\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/tornado/gen.py\", line 769, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ajimenez/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    self.log.error(\"Exception in message handler:\", exc_info=True)\n",
      "Message: 'Exception in message handler:'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "pe.forward(data['ink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ink'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9, 128,   4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"shape\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
