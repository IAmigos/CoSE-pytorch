{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.7.1\n",
      "  Using cached https://files.pythonhosted.org/packages/90/4f/acf48b3a18a8f9223c6616647f0a011a5713a985336088d7c76f3a211374/torch-1.7.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting dataclasses; python_version < \"3.7\" (from torch==1.7.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Collecting typing-extensions (from torch==1.7.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Collecting numpy (from torch==1.7.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: dataclasses, typing-extensions, numpy, torch\n",
      "Successfully installed dataclasses-0.8 numpy-1.19.5 torch-1.7.1 typing-extensions-3.7.4.3\n",
      "Collecting tfrecord\n",
      "Collecting numpy (from tfrecord)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting protobuf (from tfrecord)\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting six>=1.9 (from protobuf->tfrecord)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, six, protobuf, tfrecord\n",
      "Successfully installed numpy-1.19.5 protobuf-3.14.0 six-1.15.0 tfrecord-1.11\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.7.1\n",
    "!pip3 install tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tfrecord.torch.dataset import TFRecordDataset\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,d_model, nhead, dff, nlayers, size_embedding, dropout = 0):\n",
    "        super(Encoder, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.dense1 = nn.Linear(3, d_model)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, dff, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.dense2 = nn.Linear(d_model, size_embedding)\n",
    "        #self.init_weights()\n",
    "    \n",
    "    \n",
    "    def get_last_time_step(self, tensor, stroke_lengths):\n",
    "        \n",
    "        embeddingd_lt = []\n",
    "        \n",
    "        for pos_embedding in range(tensor.shape[0]):\n",
    "            embedding = tensor[pos_embedding, stroke_lengths[pos_embedding]-1,:]\n",
    "            embeddingd_lt.append(embedding)\n",
    "        \n",
    "        embeddingd_lt = torch.vstack(embeddingd_lt) \n",
    "        \n",
    "        return embeddingd_lt\n",
    "    \n",
    "    \n",
    "    def forward(self, src, stroke_lengths, src_mask):\n",
    "        #src = self.pos_encoder(src)\n",
    "        output = self.dense1(src)\n",
    "        output = self.transformer_encoder(output, src_mask)\n",
    "     \n",
    "        output = self.get_last_time_step(output, stroke_lengths)\n",
    "        \n",
    "        output = self.dense2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/data/jcabrera/didi_wo_text/training/\"\n",
    "name_file = \"diagrams_wo_text_20200131-00000-of-00010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = path_data + name_file\n",
    "index_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = {\"key\": \"byte\", \"label_id\":\"byte\",\n",
    "               \"ink\":\"float\", \"stroke_length\":\"int\", \"shape\":\"int\", \"num_strokes\":\"int\", \n",
    "               \"rdp_ink\":\"float\", \"rdp_stroke_length\":\"int\", \n",
    "               \"rdp_shape\":\"int\", \"rdp_num_strokes\":\"int\",\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TFRecordDataset(tfrecord_path, index_path, description)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': tensor([[ 48,  48,  51,  48,  55,  56,  57,  97,  57,  54,  97,  97, 101,  55,\n",
      "         101,  97]], dtype=torch.uint8), 'label_id': tensor([[101,  50,  51,  56,  56,  97, 100,  56,  55,  98, 102,  55,  97,  52,\n",
      "          98,  54,  49,  97,  51,  99,  52,  97,  55,  52, 102,  51,  49,  53,\n",
      "          48, 101,  51, 100,  98,  97,  57,  56,  49, 100,  49,  97]],\n",
      "       dtype=torch.uint8), 'ink': tensor([[0.1517, 0.5780, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), 'stroke_length': tensor([[ 32,  32,  25,  43, 128,  31,  33,  34,  29]], dtype=torch.int32), 'shape': tensor([[  9, 128,   4]], dtype=torch.int32), 'num_strokes': tensor([[9]], dtype=torch.int32), 'rdp_ink': tensor([[187.4000, 751.9100,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]), 'rdp_stroke_length': tensor([[38, 36, 33, 21, 29, 19, 16, 13, 16]], dtype=torch.int32), 'rdp_shape': tensor([[ 9, 38,  4]], dtype=torch.int32), 'rdp_num_strokes': tensor([[9]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(loader)\n",
    "data = dataiter.next()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d model cantidad de features: 64\n",
    "#\n",
    "xd = data[\"ink\"].reshape((9,128,4))[:,:,0:3]\n",
    "stroke_lengths = data[\"stroke_length\"].numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_lengths.reshape(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(d_model=64, nhead=4, dff=128, nlayers=6, size_embedding=256, dropout = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.to(device)\n",
    "xd = xd.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = encoder(xd, None, stroke_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 128, 3])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5168e-01, 5.7804e-01, 0.0000e+00],\n",
       "         [1.3512e-01, 5.8202e-01, 2.5000e+01],\n",
       "         [1.2253e-01, 5.8489e-01, 4.5000e+01],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.1419e+00, 8.1085e-02, 9.9100e+02],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[2.0582e+00, 6.3554e-01, 1.9720e+03],\n",
       "         [2.0203e+00, 6.3852e-01, 1.9940e+03],\n",
       "         [1.9913e+00, 6.4745e-01, 2.0140e+03],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.5922e+00, 7.5728e-01, 8.1820e+03],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[6.3466e-01, 8.2202e-01, 9.4740e+03],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[6.2584e-01, 7.1694e-01, 1.0453e+04],\n",
       "         [6.5202e-01, 7.1217e-01, 1.0503e+04],\n",
       "         [6.9524e-01, 7.0960e-01, 1.0523e+04],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]], device='cuda:1')"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6174, -0.0596, -0.6434,  ...,  0.5592, -0.4438,  1.2578],\n",
       "        [-0.6174, -0.0596, -0.6434,  ...,  0.5592, -0.4438,  1.2578],\n",
       "        [-0.7713,  0.1280, -0.3362,  ...,  0.3897, -0.3782,  1.0778],\n",
       "        ...,\n",
       "        [-0.6170, -0.0603, -0.6431,  ...,  0.5592, -0.4434,  1.2571],\n",
       "        [-0.6166, -0.0610, -0.6429,  ...,  0.5593, -0.4430,  1.2565],\n",
       "        [-0.7245,  0.0429, -0.4661,  ...,  0.4466, -0.3874,  1.1754]],\n",
       "       device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 256])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xd = xd.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1517, 0.5780],\n",
       "         [0.1351, 0.5820],\n",
       "         [0.1225, 0.5849],\n",
       "         ...,\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[1.1419, 0.0811],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[2.0582, 0.6355],\n",
       "         [2.0203, 0.6385],\n",
       "         [1.9913, 0.6474],\n",
       "         ...,\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.5922, 0.7573],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6347, 0.8220],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6258, 0.7169],\n",
       "         [0.6520, 0.7122],\n",
       "         [0.6952, 0.7096],\n",
       "         ...,\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(50,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_xd = embedding(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: pip in /home/shuaman/.local/lib/python2.7/site-packages (20.3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=4, dim_feedforward=128 ,dropout=0)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "densa = nn.Linear(2, 64)\n",
    "output = densa(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 128, 64])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_xd = embedding_xd.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer_encoder(embedding_xd, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 128, 64])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens2 = nn.Linear(64, 100)\n",
    "dens2 = dens2.to(device)\n",
    "output2 = dens2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 128, 100])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
